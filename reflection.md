Design priorities centered on safety, legibility, and predictability. The agent is intentionally constrained to SELECT-only behavior and auto-applies a row cap to prevent accidental writes or runaway scans. We kept the tool surface small (list_tables, describe_table, query_database) to make the ReAct loop easy to audit and reason about; fewer tools means fewer surprising branches during model-driven planning. The prompt injects a live schema snapshot so the model sees the exact tables and columns at runtime, which reduces hallucinated field names and guides it toward precise SQL.

Trade-offs: The minimal toolset sacrifices convenience features such as fuzzy search, autocomplete, and pagination. By forcing users (or the model) to issue explicit SQL, we gain transparency but increase brittleness to typos and schema drift. The auto-LIMIT helps safety but can hide data completeness; users might forget that results are sampled. Read-only enforcement keeps the demo safe but limits realism for workflows that require mutations, updates, or DDL changes. Also, the schema summary is baked into the system prompt at chat start; if the underlying database mutates after initialization, the prompt can go stale.

Failure modes: malformed SQL, missing tables/columns, and tool errors are surfaced as plain text; however, current behavior does not automatically retry with corrected queries. The model could still propose a non-SELECT query; the tool code rejects it, but the conversational flow may not fully explain recovery steps. Schema drift is a notable risk—if someone swaps the database or edits columns after startup, the cached schema could mislead the model. For larger tables, the naive LIMIT might still be heavy if no selective WHERE clause is used. External dependencies (Gemini API key, network availability) remain single points of failure; we only check for missing keys via dotenv and defer API failures to runtime.

Mitigations considered: (1) A schema-refresh tool that regenerates the prompt snippet on demand would reduce drift. (2) A safe SQL linter or template generator could intercept non-SELECT or unindexed scans before execution. (3) Adding few-shot exemplars for common recovery paths (e.g., retry with a corrected column name) could improve robustness without broadening the tool surface. (4) Lightweight pagination parameters (offset/limit) and sampling modes would make large-table exploration cheaper. (5) Caching recent observations could let the model reuse earlier results rather than re-querying the database.

Future directions: introduce authorization controls per tool to model multi-tenant data safety; add telemetry for which queries the agent issues and how often errors occur; enrich the prompt with compact stats (row counts, min/max dates) to steer better filters; and provide optional parameterized query templates to reduce SQL brittleness while preserving transparency. A more advanced version could support write operations behind an explicit “transaction” tool that requires confirmation, coupled with automatic rollbacks on errors. Finally, integrating unit tests that mock tool calls (not just DB hits) would help validate reasoning structure under failure conditions.
